[
  {
    "objectID": "notebooks/my-notebook.html",
    "href": "notebooks/my-notebook.html",
    "title": "Deb Bose",
    "section": "",
    "text": "\"\"\"\nSimple script to download US Individual Income Tax / GDP data from FRED\nNo complex dependencies - just pandas and requests\n\"\"\"\n\nimport pandas as pd\nimport requests\nfrom io import StringIO\n\nprint(\"Downloading US Individual Income Tax and GDP data from FRED...\")\nprint(\"=\" * 80)\n\n# FRED series IDs\n# W006RC1Q027SBEA = Individual Income Tax Receipts (quarterly, billions)\n# GDP = Gross Domestic Product (quarterly, billions)\n\ndef download_fred_series(series_id, series_name):\n    \"\"\"Download a single series from FRED as CSV.\"\"\"\n    url = f\"https://fred.stlouisfed.org/graph/fredgraph.csv?id={series_id}\"\n    \n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        \n        # Read CSV\n        df = pd.read_csv(StringIO(response.text))\n        df.columns = ['DATE', series_name]\n        df['DATE'] = pd.to_datetime(df['DATE'])\n        df[series_name] = pd.to_numeric(df[series_name], errors='coerce')\n        \n        print(f\"✓ Downloaded {series_name}: {len(df)} observations\")\n        return df\n    \n    except Exception as e:\n        print(f\"✗ Error downloading {series_name}: {e}\")\n        return None\n\n# Download data\nprint(\"\\n1. Downloading Individual Income Tax receipts...\")\ntax_df = download_fred_series('W006RC1Q027SBEA', 'IndividualIncomeTax')\n\nDownloading US Individual Income Tax and GDP data from FRED...\n================================================================================\n\n1. Downloading Individual Income Tax receipts...\n✓ Downloaded IndividualIncomeTax: 315 observations\n\n\n\ntax_df.tail()\n\n\n\n\n\n\n\n\nDATE\nIndividualIncomeTax\n\n\n\n\n310\n2024-07-01\n3141.087\n\n\n311\n2024-10-01\n3202.119\n\n\n312\n2025-01-01\n3246.051\n\n\n313\n2025-04-01\n3455.060\n\n\n314\n2025-07-01\n3599.024\n\n\n\n\n\n\n\n\ntax_df_indexed = tax_df.set_index(\"DATE\")\n\n\nimport pandas as pd\n\ndef to_annual_series(\n    tax_df: pd.DataFrame,\n    date_col: str = \"DATE\",\n    value_col: str = \"IndividualIncomeTax\",\n    agg: str = \"mean\",  # \"mean\" (default) or \"sum\"\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert a quarterly (or higher frequency) dataframe with a DATE column\n    into an annual dataframe with columns: Year, IndividualIncomeTax_Annual.\n\n    agg:\n      - \"mean\": good for level/rate-like series (e.g., % of GDP, index levels, rates)\n      - \"sum\" : good for flow series (e.g., revenues within year)\n    \"\"\"\n    df = tax_df.copy()\n\n    # If DATE is the index, bring it back as a column\n    if date_col not in df.columns and df.index.name == date_col:\n        df = df.reset_index()\n\n    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n    df = df.dropna(subset=[date_col, value_col])\n\n    df[\"Year\"] = df[date_col].dt.year.astype(int)\n\n    if agg not in (\"mean\", \"sum\", \"median\"):\n        raise ValueError(\"agg must be one of: 'mean', 'sum', 'median'\")\n\n    annual = (\n        df.groupby(\"Year\", as_index=False)[value_col]\n          .agg({f\"{value_col}_Annual\": agg})\n          .sort_values(\"Year\")\n          .reset_index(drop=True)\n    )\n    return annual\n\n\nannual_tax = to_annual_series(tax_df, value_col=\"IndividualIncomeTax\", agg=\"mean\")\nannual_tax.tail()\n\n\n\n\n\n\n\n\nYear\nIndividualIncomeTax_Annual\n\n\n\n\n74\n2021\n2675.071500\n\n\n75\n2022\n3252.924000\n\n\n76\n2023\n2918.060500\n\n\n77\n2024\n3118.884750\n\n\n78\n2025\n3433.378333\n\n\n\n\n\n\n\n\ncpi_df = download_fred_series('CPIAUCSL', 'CPI')\ncpi_df.tail()\nannual_cpi = to_annual_series(tax_df, value_col=\"CPI\", agg=\"mean\")\nannual_cpi.tail()\n\n✓ Downloaded CPI: 947 observations\n\n\n\n\n\n\n\n\n\nYear\nCPI_Annual\n\n\n\n\n74\n2021\n270.967917\n\n\n75\n2022\n292.625417\n\n\n76\n2023\n304.704167\n\n\n77\n2024\n313.697833\n\n\n78\n2025\n321.577200\n\n\n\n\n\n\n\n\n# Step 2: Merge with your tax data\ndf = pd.merge(annual_tax, annual_cpi_df, on='Year', how='inner')\ndf.tail()\n\n\n\n\n\n\n\n\nYear\nIndividualIncomeTax_Annual\nCPI_Annual\n\n\n\n\n74\n2021\n2675.071500\n270.967917\n\n\n75\n2022\n3252.924000\n292.625417\n\n\n76\n2023\n2918.060500\n304.704167\n\n\n77\n2024\n3118.884750\n313.697833\n\n\n78\n2025\n3433.378333\n321.577200\n\n\n\n\n\n\n\n\n# Step 3: Calculate Real Tax (in 2024 dollars)\nlatest_cpi = annual_cpi[annual_cpi['Year'] == 2024]['CPI_Annual'].mean()\ndf['Real_Tax'] = (df['IndividualIncomeTax_Annual'] / df['CPI_Annual']) * latest_cpi\ndf.tail()\n\n\n\n\n\n\n\n\nYear\nIndividualIncomeTax_Annual\nCPI_Annual\nReal_Tax\n\n\n\n\n74\n2021\n2675.071500\n270.967917\n3096.913258\n\n\n75\n2022\n3252.924000\n292.625417\n3487.172175\n\n\n76\n2023\n2918.060500\n304.704167\n3004.190151\n\n\n77\n2024\n3118.884750\n313.697833\n3118.884750\n\n\n78\n2025\n3433.378333\n321.577200\n3349.252821\n\n\n\n\n\n\n\n\ndf = df.set_index('Year')\ndf['Real_Tax'].plot()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.api import OLS, add_constant\nfrom scipy import stats\n\ndef chow_test_tax_series(\n    df_annual: pd.DataFrame,\n    y_col: str,\n    break_year: int = 1971,\n    min_obs_each_side: int = 8,\n    save_csv_path: str = None\n):\n    \"\"\"\n    Chow test for a structural break at a known year on an annual series.\n\n    Model: y ~ const + t\n    where t is a normalized year index for numerical stability.\n\n    H0: No structural break (β_pre = β_post)\n    H1: Structural break exists\n    \"\"\"\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"CHOW TEST FOR STRUCTURAL BREAK\")\n    print(\"=\" * 80)\n\n    # Clean and keep what we need\n    df_clean = df_annual[[\"Year\", y_col]].dropna().copy()\n    df_clean = df_clean.sort_values(\"Year\").reset_index(drop=True)\n\n    # Split (match your original: pre &lt; break_year, post &gt;= break_year)\n    df_pre = df_clean[df_clean[\"Year\"] &lt; break_year].copy()\n    df_post = df_clean[df_clean[\"Year\"] &gt;= break_year].copy()\n\n    n_pre, n_post = len(df_pre), len(df_post)\n    n_total = n_pre + n_post\n\n    print(f\"\\nBreak year: {break_year}\")\n    print(f\"Observations pre-break: {n_pre}\")\n    print(f\"Observations post-break: {n_post}\")\n    print(f\"Total observations: {n_total}\")\n\n    if n_pre &lt; min_obs_each_side or n_post &lt; min_obs_each_side:\n        raise ValueError(\n            f\"Not enough annual observations on each side of {break_year}. \"\n            f\"Need at least {min_obs_each_side} each side. Got pre={n_pre}, post={n_post}.\"\n        )\n\n    # Normalize time index for stability (use the same reference for all)\n    base_year = df_clean[\"Year\"].min()\n    df_clean[\"t\"] = df_clean[\"Year\"] - base_year\n    df_pre[\"t\"] = df_pre[\"Year\"] - base_year\n    df_post[\"t\"] = df_post[\"Year\"] - base_year\n\n    # Pooled regression\n    X_pooled = add_constant(df_clean[\"t\"].astype(float))\n    y_pooled = df_clean[y_col].astype(float)\n    model_pooled = OLS(y_pooled, X_pooled).fit()\n    RSS_pooled = float(model_pooled.ssr)\n\n    # Separate regressions\n    X_pre = add_constant(df_pre[\"t\"].astype(float))\n    y_pre = df_pre[y_col].astype(float)\n    model_pre = OLS(y_pre, X_pre).fit()\n    RSS_pre = float(model_pre.ssr)\n\n    X_post = add_constant(df_post[\"t\"].astype(float))\n    y_post = df_post[y_col].astype(float)\n    model_post = OLS(y_post, X_post).fit()\n    RSS_post = float(model_post.ssr)\n\n    RSS_separate = RSS_pre + RSS_post\n\n    # Chow statistic\n    k = 2  # intercept + slope\n    df_num = k\n    df_den = n_total - 2 * k\n\n    F_stat = ((RSS_pooled - RSS_separate) / k) / (RSS_separate / df_den)\n    p_value = 1 - stats.f.cdf(F_stat, df_num, df_den)\n\n    critical_05 = stats.f.ppf(0.95, df_num, df_den)\n    critical_01 = stats.f.ppf(0.99, df_num, df_den)\n\n    print(\"\\n\" + \"-\" * 80)\n    print(\"RESULTS:\")\n    print(\"-\" * 80)\n    print(f\"\\nRSS Pooled (restricted): {RSS_pooled:.4f}\")\n    print(f\"RSS Separate (unrestricted): {RSS_separate:.4f}\")\n    print(f\"  RSS Pre-break: {RSS_pre:.4f}\")\n    print(f\"  RSS Post-break: {RSS_post:.4f}\")\n\n    print(f\"\\nChow F-statistic: {F_stat:.4f}\")\n    print(f\"Degrees of freedom: ({df_num}, {df_den})\")\n    print(f\"P-value: {p_value:.6f}\")\n\n    print(f\"\\nCritical values:\")\n    print(f\"  5% level: {critical_05:.4f}\")\n    print(f\"  1% level: {critical_01:.4f}\")\n\n    print(\"\\nConclusion:\")\n    if p_value &lt; 0.01:\n        result = \"Reject H0 (1%)\"\n        print(f\"  *** REJECT NULL HYPOTHESIS at 1% level ***\")\n        print(f\"  Strong evidence of structural break at {break_year}\")\n    elif p_value &lt; 0.05:\n        result = \"Reject H0 (5%)\"\n        print(f\"  ** REJECT NULL HYPOTHESIS at 5% level **\")\n        print(f\"  Significant evidence of structural break at {break_year}\")\n    elif p_value &lt; 0.10:\n        result = \"Reject H0 (10%)\"\n        print(f\"  * REJECT NULL HYPOTHESIS at 10% level *\")\n        print(f\"  Moderate evidence of structural break at {break_year}\")\n    else:\n        result = \"Fail to Reject H0\"\n        print(f\"  FAIL TO REJECT NULL HYPOTHESIS\")\n        print(f\"  Insufficient evidence of structural break at {break_year}\")\n\n    # Coefficients\n    print(\"\\n\" + \"-\" * 80)\n    print(\"REGRESSION COEFFICIENTS:\")\n    print(\"-\" * 80)\n\n    print(f\"\\nPre-{break_year} period:\")\n    print(f\"  Intercept: {model_pre.params.iloc[0]:.4f} (se: {model_pre.bse.iloc[0]:.4f})\")\n    print(f\"  Slope:     {model_pre.params.iloc[1]:.4f} (se: {model_pre.bse.iloc[1]:.4f})\")\n    print(f\"  R-squared: {model_pre.rsquared:.4f}\")\n\n    print(f\"\\nPost-{break_year} period:\")\n    print(f\"  Intercept: {model_post.params.iloc[0]:.4f} (se: {model_post.bse.iloc[0]:.4f})\")\n    print(f\"  Slope:     {model_post.params.iloc[1]:.4f} (se: {model_post.bse.iloc[1]:.4f})\")\n    print(f\"  R-squared: {model_post.rsquared:.4f}\")\n\n    print(f\"\\nPooled (no break):\")\n    print(f\"  Intercept: {model_pooled.params.iloc[0]:.4f} (se: {model_pooled.bse.iloc[0]:.4f})\")\n    print(f\"  Slope:     {model_pooled.params.iloc[1]:.4f} (se: {model_pooled.bse.iloc[1]:.4f})\")\n    print(f\"  R-squared: {model_pooled.rsquared:.4f}\")\n\n    results_dict = {\n        \"Test\": \"Chow Test\",\n        \"Series\": y_col,\n        \"Break Year\": break_year,\n        \"F-statistic\": float(F_stat),\n        \"P-value\": float(p_value),\n        \"Critical Value (5%)\": float(critical_05),\n        \"Critical Value (1%)\": float(critical_01),\n        \"Result\": result,\n        \"Slope Pre\": float(model_pre.params.iloc[1]),\n        \"Slope Post\": float(model_post.params.iloc[1]),\n        \"Slope Change\": float(model_post.params.iloc[1] - model_pre.params.iloc[1]),\n        \"n_pre\": int(n_pre),\n        \"n_post\": int(n_post),\n    }\n\n    if save_csv_path is not None:\n        pd.DataFrame([results_dict]).to_csv(save_csv_path, index=False)\n\n    return results_dict\n\n\n# Chow test at 1971\nres = chow_test_tax_series(\n    df,\n    y_col=\"Real_Tax\",\n    break_year=1971\n)\n\nres\n\n\n================================================================================\nCHOW TEST FOR STRUCTURAL BREAK\n================================================================================\n\nBreak year: 1971\nObservations pre-break: 24\nObservations post-break: 55\nTotal observations: 79\n\n--------------------------------------------------------------------------------\nRESULTS:\n--------------------------------------------------------------------------------\n\nRSS Pooled (restricted): 3811995.5571\nRSS Separate (unrestricted): 3034840.0098\n  RSS Pre-break: 84072.8198\n  RSS Post-break: 2950767.1900\n\nChow F-statistic: 9.6029\nDegrees of freedom: (2, 75)\nP-value: 0.000194\n\nCritical values:\n  5% level: 3.1186\n  1% level: 4.8999\n\nConclusion:\n  *** REJECT NULL HYPOTHESIS at 1% level ***\n  Strong evidence of structural break at 1971\n\n--------------------------------------------------------------------------------\nREGRESSION COEFFICIENTS:\n--------------------------------------------------------------------------------\n\nPre-1971 period:\n  Intercept: 477.9496 (se: 24.4684)\n  Slope:     27.4835 (se: 1.8229)\n  R-squared: 0.9118\n\nPost-1971 period:\n  Intercept: 2.3028 (se: 107.0530)\n  Slope:     37.3621 (se: 2.0042)\n  R-squared: 0.8677\n\nPooled (no break):\n  Intercept: 349.9247 (se: 49.5949)\n  Slope:     31.2690 (se: 1.0978)\n  R-squared: 0.9133\n\n\n{'Test': 'Chow Test',\n 'Series': 'Real_Tax',\n 'Break Year': 1971,\n 'F-statistic': 9.602922372192094,\n 'P-value': 0.00019358783729239715,\n 'Critical Value (5%)': 3.118642128006125,\n 'Critical Value (1%)': 4.899877423111457,\n 'Result': 'Reject H0 (1%)',\n 'Slope Pre': 27.483480442522755,\n 'Slope Post': 37.362148635986124,\n 'Slope Change': 9.878668193463369,\n 'n_pre': 24,\n 'n_post': 55}"
  },
  {
    "objectID": "posts/2026-01-06-my-first-post.html",
    "href": "posts/2026-01-06-my-first-post.html",
    "title": "My first Quarto post",
    "section": "",
    "text": "Some text.\nInline math: \\(I_t = f(1/C_t)\\)\nimport math math.sqrt(2)\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deb Bose",
    "section": "",
    "text": "Articles: essays, market notes, technical deep dives\n\nNotebooks: runnable research with code + charts\n\nPapers: PDFs + references\n\nProjects: links to my GitHub work\n\n\n\n\nGo to Articles"
  },
  {
    "objectID": "index.html#what-youll-find-here",
    "href": "index.html#what-youll-find-here",
    "title": "Deb Bose",
    "section": "",
    "text": "Articles: essays, market notes, technical deep dives\n\nNotebooks: runnable research with code + charts\n\nPapers: PDFs + references\n\nProjects: links to my GitHub work\n\n\n\n\nGo to Articles"
  }
]